{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-process",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code mostly reproduces Elsa Arcaute's R practical for igraph in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-alaska",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import igraph as ig\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "% matplotlib inline\n",
    "nx.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-minimum",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-cover",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the shapefile using geopandas\n",
    "tube_shp = gpd.read_file(r'underground/underground.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-screw",
   "metadata": {},
   "outputs": [],
   "source": [
    "tube_shp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Immediately we can derive a plot of the shapefile.\n",
    "# However, this representation doesn't currently include any actual network information\n",
    "# It's just a drawing of lines on a chart!\n",
    "tube_shp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infectious-huntington",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are a few descriptive queries, following Elsa's example\n",
    "\n",
    "# What is the maximum distance between stations?\n",
    "tube_shp['distance'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-palace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which are the stations that are furthest apart?\n",
    "tube_shp[tube_shp['distance'] == tube_shp['distance'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-crown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some pairs of stations appear multiple times, why?\n",
    "# e.g. node 11 - due to the different lines that pass through the station.\n",
    "tube_shp[tube_shp['station_1'] == 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-lucas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also select the same information by station name:\n",
    "tube_shp[tube_shp['station_1_'] == 'Baker Street']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are worried about not getting all instances, due to issues with spaces etc. use regular expressions\n",
    "# pandas does this nicely with string functions.\n",
    "# NB the ^ means that the pattern 'Baker' must occur at the beginning of the text e.g. 'Baker Street' not 'West baker Street'.\n",
    "tube_shp[tube_shp['station_1_'].str.contains(r'^Baker')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-robert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to extract the actual station locations from these data.\n",
    "# We'd like the id and name of each station, and the starting point of the line representing the connection.\n",
    "# Here's an approximation of the way it's done in the R code, which uses tidy() from broom.\n",
    "\n",
    "# First we need to get the start and end lons and lats from the line geometry\n",
    "tube_shp['start_lon'] = tube_shp.geometry.apply(lambda x: x.coords[0][0])\n",
    "tube_shp['start_lat'] = tube_shp.geometry.apply(lambda x: x.coords[0][1])\n",
    "tube_shp['end_lon'] = tube_shp.geometry.apply(lambda x: x.coords[1][0])\n",
    "tube_shp['end_lat'] = tube_shp.geometry.apply(lambda x: x.coords[1][1])\n",
    "\n",
    "# Now we'll create a new pandas dataframe with just the first stations\n",
    "firstStation = tube_shp[['station_1','station_1_','start_lon','start_lat']].copy()\n",
    "# Rename the columns to align with the R example\n",
    "firstStation.rename(columns = {'station_1':'id','station_1_':'name','start_lon':'long','start_lat':'lat'} ,inplace = True)\n",
    "\n",
    "# And again for the second stations\n",
    "secondStation = tube_shp[['station_2','station_2_','end_lon','end_lat']].copy()\n",
    "# Rename the columns to align with the R example\n",
    "secondStation.rename(columns = {'station_2':'id','station_2_':'name','end_lon':'long','end_lat':'lat'} ,inplace = True)\n",
    "\n",
    "# Now append the two dataframes\n",
    "stations = firstStation.append(secondStation)\n",
    "\n",
    "# Finally remove the duplicate stations by their id - there are 306 unique stations.\n",
    "stations.drop_duplicates('id', inplace= True)\n",
    "\n",
    "# We need these stations and coordinates so that we can locate the stations in space when we create a network graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-portrait",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't like working in a geographic coordinate system that much.\n",
    "#Let's also create a version of stations using the British National Grid.\n",
    "from shapely.geometry import Point\n",
    "stations_BNG = gpd.GeoDataFrame(stations, geometry = stations.apply(lambda x: Point(x['long'],x['lat']) , axis=1).values)\n",
    "# Set original crs as WGS84\n",
    "stations_BNG.crs = {'init':'epsg:4326'}\n",
    "# Now project to BNG\n",
    "stations_BNG = stations_BNG.to_crs({'init':'epsg:27700'})\n",
    "# Finally extract points to columns\n",
    "stations_BNG['X'] = stations_BNG['geometry'].x\n",
    "stations_BNG['Y'] = stations_BNG['geometry'].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-system",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets construct the network\n",
    "# NB have to use a multigraph here to preserve all of the edges - e.g. where circle and district are the same etc.\n",
    "g_tube = nx.from_pandas_edgelist(tube_shp,'station_1','station_2',edge_attr = 'distance', create_using=nx.MultiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-publisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick plot\n",
    "f, (ax1,ax2) = plt.subplots(1,2,figsize = (16,8))\n",
    "\n",
    "# Draw the tube network using the defaults - a spring layout, I think.\n",
    "nx.draw(g_tube,ax=ax1)\n",
    "\n",
    "# convert the stations info to a dictionary of positions\n",
    "pos = stations[['id','long','lat']].set_index('id').T.to_dict('list')\n",
    "\n",
    "# Draw while assigning spatial locations to the points\n",
    "# Now it looks like the original shapefile plot!\n",
    "nx.draw(g_tube,pos=pos, ax = ax2)\n",
    "ax2.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-insertion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can't really see anything, so let's improve the visualisation of the spatially embedded network\n",
    "# Still not great, but much improved!\n",
    "f, ax = plt.subplots(figsize=(14,8))\n",
    "nx.draw(g_tube,pos=pos, ax = ax, node_size = 20, node_color = 'w', with_labels=True, font_size = 8)\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try drawing the graph, but using projected coordinates\n",
    "# convert the stations_bng info to a dictionary of positions\n",
    "pos_bng = stations_BNG[['id','X','Y']].set_index('id').T.to_dict('list')\n",
    "f, ax = plt.subplots(figsize=(14,8))\n",
    "nx.draw(g_tube,pos=pos_bng, ax = ax, node_size = 20, node_color = 'w', with_labels=True, font_size = 8)\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-catholic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anyway, let's look at some properties of the graph\n",
    "\n",
    "# Number of stations\n",
    "g_tube.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-knife",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of edges\n",
    "g_tube.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of islands or disconnected components\n",
    "nx.number_connected_components(g_tube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-ecology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unweighted diameter (topological diameter)\n",
    "nx.diameter(g_tube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-relations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted diameter, using eccentricity and dictionary of shortest paths\n",
    "e = nx.eccentricity(g_tube, sp = dict(nx.shortest_path_length(g_tube,weight='distance')))\n",
    "nx.diameter(g_tube,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-baptist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute betweenness - for multigraphs networkx only computes the topological betweenness.\n",
    "# This happens even if the weight parameter is set.\n",
    "# returns a dictionary\n",
    "bet_tube = nx.betweenness_centrality(g_tube)\n",
    "\n",
    "# make bet_london a pandas dataframe for ease\n",
    "bet_tube = pd.DataFrame.from_dict(bet_tube, orient='index')\n",
    "\n",
    "f, ax = plt.subplots(figsize=(16,10))\n",
    "nx.draw(g_tube,pos=pos_bng, ax = ax, node_size = bet_tube/bet_tube.max()*100, cmap = 'hot', node_color = bet_tube[0])\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's add the names of the stations to the graph\n",
    "name_dict = stations[['id','name']].set_index('id').to_dict()['name']\n",
    "# To add names, do this, but it's not strictly necessary for labelling.\n",
    "nx.set_node_attributes(g_tube, name_dict, 'name')\n",
    "\n",
    "# Now plot with labels\n",
    "f, ax = plt.subplots(figsize=(16,10))\n",
    "nx.draw(g_tube, pos=pos_bng, ax = ax, node_size = 50, node_color = 'xkcd:sky blue', with_labels=True, labels= name_dict, font_size = 8)\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently, our multigraph has are several pairs stations connected by multiple lines.\n",
    "# We can simplify the Graph to remove duplicate edges.\n",
    "g_london = nx.Graph()\n",
    "for u,v,data in g_tube.edges(data=True):\n",
    "    w = data['distance']\n",
    "    if g_london.has_edge(u,v):\n",
    "        # If edge exists use the smallest distance as the weight\n",
    "        if w < g_london[u][v]['distance']:\n",
    "            g_london[u][v]['distance'] = w\n",
    "    else:\n",
    "        g_london.add_edge(u, v, distance=w)\n",
    "\n",
    "# Add node names back in for earlier name dictionary\n",
    "nx.set_node_attributes(g_london, name_dict, 'name')\n",
    "        \n",
    "# NB g_london = nx.Graph(g_tube) also works, but you can't change way edge data are assigned.\n",
    "# This means that the weights etc. will simply be the ones that are seen first.\n",
    "\n",
    "# Now plot with labels\n",
    "f, ax = plt.subplots(figsize=(16,10))\n",
    "nx.draw(g_london, pos=pos_bng, ax = ax, node_size = 50, node_color = 'xkcd:sky blue', with_labels=True, labels= name_dict, font_size = 8)\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to calculate weighted betweenness, specify weight, the default is none.\n",
    "# Adding distances may change shortest paths compared to the topological case where each edge is of value 1.\n",
    "#Compute betweenness - returns a dictionary\n",
    "bet_london = nx.betweenness_centrality(g_london, weight = 'distance')\n",
    "\n",
    "# make bet_london a pandas dataframe for ease\n",
    "bet_london = pd.DataFrame.from_dict(bet_london, orient='index')\n",
    "\n",
    "f, ax = plt.subplots(figsize=(16,10))\n",
    "nx.draw(g_london,pos=pos_bng, ax = ax, node_size = bet_london/bet_london.max()*100, cmap = 'hot', node_color = bet_london[0])\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-angola",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge betweenness - with edge weights as distance.\n",
    "ebet_lon = nx.edge_betweenness_centrality(g_london, weight='distance')\n",
    "\n",
    "f, ax = plt.subplots(figsize=(16,10))\n",
    "nx.draw(g_london,pos=pos_bng, ax = ax, node_size = 10, node_color = 'k', edgelist = ebet_lon.keys(), \n",
    "        edge_color = ebet_lon.values(),edge_cmap = plt.cm.hot, width = np.array(ebet_lon.values())/max(ebet_lon.values())*10)\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-toner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#closeness, with distance specified for shortest paths. Automatically normalised.\n",
    "clos_london = nx.closeness_centrality(g_london, distance = 'distance')\n",
    "\n",
    "# make clos_london a pandas dataframe for ease of use\n",
    "clos_london = pd.DataFrame.from_dict(clos_london, orient='index')\n",
    "\n",
    "# Plot the centrality on the graph\n",
    "f, ax = plt.subplots(figsize=(16,10))\n",
    "nx.draw(g_london,pos=pos_bng, ax = ax, node_size = 75, cmap = 'inferno', node_color = clos_london[0])\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-doctrine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topological closeness. Automatically normalised.\n",
    "clos_london = nx.closeness_centrality(g_london)\n",
    "\n",
    "# make clos_london a pandas dataframe for ease of use\n",
    "clos_london = pd.DataFrame.from_dict(clos_london, orient='index')\n",
    "\n",
    "# Plot the centrality on the graph\n",
    "f, ax = plt.subplots(figsize=(16,10))\n",
    "nx.draw(g_london,pos=pos_bng, ax = ax, node_size = 75, cmap = 'inferno', node_color = clos_london[0])\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-organization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise:\n",
    " \n",
    "# 1) Remove nodes according to a selected property: e.g. degree, closeness centrality and betweenness centrality\n",
    "\n",
    "# 2) think about the effects on the network of removing such nodes. Which have more impact on the network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-wales",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to remove nodes, first identify nodes by 'name' to get their ids.\n",
    "del_nodes = filter(lambda (n, d): d['name'] in ['Baker Street','Embankment'], g_london.nodes(data=True))\n",
    "\n",
    "# NB removal is in place\n",
    "g_london_1 = deepcopy(g_london)\n",
    "g_london_1.remove_nodes_from([x[0] for x in del_nodes])\n",
    "\n",
    "g_london.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-corrections",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_tube = ig.Graph(directed = False)\n",
    "\n",
    "# The stations represent the possible nodes\n",
    "# I have to cast the ids as strings as otherwise they get assigned as node ids, which have to start from 0.\n",
    "g_tube.add_vertices(stations['id'].values.astype(str))\n",
    "\n",
    "# Now take the edge list and add edges. Agin as string to match names.\n",
    "g_tube.add_edges(tube_shp[['station_1','station_2']].values.astype('str'))\n",
    "\n",
    "# Finally add edge weights\n",
    "g_tube.es['weight'] = tube_shp['distance'].values\n",
    "\n",
    "# Now, a basic plot\n",
    "ig.plot(g_tube, layout = g_tube.layout_drl(),bbox =(400,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add in some geographic locations for this plot and tidy up the nodes\n",
    "# NB Have to multiply y-axis coordinates by -1 as Cairo plots from top left, not bottom left. \n",
    "\n",
    "#pos = ig.Layout(stations[['long','lat']].apply(lambda x: (x['long'],x['lat']*-1.0),axis=1).tolist())\n",
    "pos = ig.Layout(stations_BNG[['X','Y']].apply(lambda x: (x['X'],x['Y']*-1.0),axis=1).tolist())\n",
    "\n",
    "# Set 'label' to vertex 'name'\n",
    "g_tube.vs['label'] = g_tube.vs['name']\n",
    "\n",
    "# This looks a bit better!\n",
    "ig.plot(g_tube, layout = pos, vertex_size = 3, vertex_color = 'white', vertex_label_size = 8, bbox =(500,350))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-breakfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anyway, let's look at some properties of the graph\n",
    "\n",
    "# Number of stations\n",
    "len(g_tube.vs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of edges\n",
    "len(g_tube.es())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of islands or disconnected components\n",
    "len(g_tube.clusters().subgraphs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diameter accounting for edge weights\n",
    "g_tube.diameter(weights='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unweighted or 'topological' diameter\n",
    "g_tube.diameter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-combination",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute betweenness\n",
    "bet_london = g_tube.betweenness(directed = False, weights = 'weight')\n",
    "\n",
    "# Remove labelling for now.\n",
    "del g_tube.vs['label']\n",
    "\n",
    "# I'm going to use matplotlib to work out my colours for me!\n",
    "# First normalize the data\n",
    "norm = (np.array(bet_london) - min(bet_london)) / (max(bet_london) - min(bet_london))\n",
    "# Now get a colourmap\n",
    "cmap = plt.cm.get_cmap('hot')\n",
    "# Now get rgb values, but throw away opacity, and map to a list of tuples\n",
    "palette = map(tuple,cmap(norm)[:,0:3])\n",
    "\n",
    "ig.plot(g_tube, layout = pos, vertex_size = np.array(bet_london)/max(bet_london) * 10, vertex_color = palette, bbox =(500,350))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-ocean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the station names to the vertices\n",
    "g_tube.vs['station'] = stations['name'].values.astype('S')\n",
    "\n",
    "# Set 'label' to vertex 'station'\n",
    "g_tube.vs['label'] = g_tube.vs['station']\n",
    "\n",
    "# Plot with labels\n",
    "ig.plot(g_tube, layout = pos, vertex_size = 3, vertex_color = 'white', vertex_label_size = 6, bbox =(500,350))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-breast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When there are many lines connecting pairs, we get multiple entries.\n",
    "# We can simplify the network as follows:\n",
    "g_london = g_tube.simplify(loops = True, multiple = True, combine_edges= 'min')\n",
    "\n",
    "# Now compute topological betweenness (i.e. unweighted)\n",
    "bet_london = g_tube.betweenness(directed = False, weights = None)\n",
    "\n",
    "# Remove labelling for now.\n",
    "del g_tube.vs['label']\n",
    "\n",
    "# I'm going to use matplotlib to work out my colours for me!\n",
    "# First normalize the data\n",
    "norm = (np.array(bet_london) - min(bet_london)) / (max(bet_london) - min(bet_london))\n",
    "# Now get a colourmap\n",
    "cmap = plt.cm.get_cmap('hot')\n",
    "# Now get rgb values, but throw away opacity, and map to a list of tuples\n",
    "palette = map(tuple,cmap(norm)[:,0:3])\n",
    "\n",
    "ig.plot(g_tube, layout = pos, vertex_size = np.array(bet_london)/max(bet_london) * 10, vertex_color = palette, bbox =(500,350))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-railway",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge betweenness with weights\n",
    "edge_bet_london = g_london.edge_betweenness(weights='weight')\n",
    "\n",
    "# Normalize the data\n",
    "norm = (np.array(edge_bet_london) - min(edge_bet_london)) / (max(edge_bet_london) - min(edge_bet_london))\n",
    "# Now get a colourmap\n",
    "cmap = plt.cm.get_cmap('hot')\n",
    "# Now get rgb values, but throw away opacity, and map to a list of tuples\n",
    "palette = map(tuple,cmap(norm)[:,0:3])\n",
    "\n",
    "ig.plot(g_tube, layout = pos, edge_width = np.array(edge_bet_london)/max(edge_bet_london) * 10, edge_color = palette, \n",
    "        vertex_size = 1.5,  bbox =(500,350))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# closeness\n",
    "clos_london = g_london.closeness(weights= 'weight')\n",
    "\n",
    "# First normalize the data 0-1\n",
    "norm = (np.array(clos_london) - min(clos_london)) / (max(clos_london) - min(clos_london))\n",
    "# Now get a colourmap\n",
    "cmap = plt.cm.get_cmap('inferno')\n",
    "# Now get rgb values, but throw away opacity, and map to a list of tuples\n",
    "palette = map(tuple,cmap(norm)[:,0:3])\n",
    "\n",
    "ig.plot(g_tube, layout = pos, vertex_size = 6, vertex_color = palette, bbox =(500,350))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urbsim",
   "language": "python",
   "name": "urbsim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
